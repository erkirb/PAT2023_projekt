{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44380b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('ST_train_feature_final.csv')\n",
    "#df = pd.read_csv('ST_test_feature_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7029a949",
   "metadata": {},
   "source": [
    "**LogisticRegression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6de6c5a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy: 0.7832087406555491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.74      0.77       861\n",
      "        True       0.77      0.82      0.79       878\n",
      "\n",
      "    accuracy                           0.78      1739\n",
      "   macro avg       0.78      0.78      0.78      1739\n",
      "weighted avg       0.78      0.78      0.78      1739\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erkir\\anaconda3\\envs\\PAT23\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[('num', StandardScaler(), numerical_features),('cat', OneHotEncoder(), categorical_features)])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"LogisticRegression accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df725883",
   "metadata": {},
   "source": [
    "**DecisionTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c1e923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree accuracy: 0.7521564117308798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.75      0.75       861\n",
      "        True       0.75      0.76      0.75       878\n",
      "\n",
      "    accuracy                           0.75      1739\n",
      "   macro avg       0.75      0.75      0.75      1739\n",
      "weighted avg       0.75      0.75      0.75      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', DecisionTreeClassifier(random_state=42))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"DecisionTree accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86222dc2",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0cfb7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest accuracy: 0.79700977573318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.82      0.80       861\n",
      "        True       0.82      0.77      0.79       878\n",
      "\n",
      "    accuracy                           0.80      1739\n",
      "   macro avg       0.80      0.80      0.80      1739\n",
      "weighted avg       0.80      0.80      0.80      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', RandomForestClassifier(random_state=42))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"RandomForest accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c07619",
   "metadata": {},
   "source": [
    "**Gradient Boosting Machines (GBM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c6e3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Machine accuracy: 0.7947096032202415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.76      0.79       861\n",
      "        True       0.78      0.83      0.80       878\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.80      0.79      0.79      1739\n",
      "weighted avg       0.80      0.79      0.79      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', GradientBoostingClassifier(random_state=42))])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Gradient Boosting Machine accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3372aee8",
   "metadata": {},
   "source": [
    "**Support Vector Machines (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c96b797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine accuracy: 0.7878090856814262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.77      0.78       861\n",
      "        True       0.78      0.80      0.79       878\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.79      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with an SVM classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', SVC(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Support Vector Machine accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74afbc5",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "196ce640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors accuracy: 0.7699827487061529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.75      0.79      0.77       861\n",
      "        True       0.79      0.75      0.77       878\n",
      "\n",
      "    accuracy                           0.77      1739\n",
      "   macro avg       0.77      0.77      0.77      1739\n",
      "weighted avg       0.77      0.77      0.77      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with a KNN classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"K-Nearest Neighbors accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf87aa3",
   "metadata": {},
   "source": [
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9c723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes accuracy: 0.7596319723979299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.73      0.75       861\n",
      "        True       0.75      0.79      0.77       878\n",
      "\n",
      "    accuracy                           0.76      1739\n",
      "   macro avg       0.76      0.76      0.76      1739\n",
      "weighted avg       0.76      0.76      0.76      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline with a Naive Bayes classifier\n",
    "# Using GaussianNB for numerical features and CategoricalNB for categorical features\n",
    "#pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "#                           ('classifier', GaussianNB())])  # Use CategoricalNB() if your features are primarily categorical\n",
    "\n",
    "to_dense_transformer = FunctionTransformer(lambda x: x.toarray(), accept_sparse=True)\n",
    "\n",
    "# Create a pipeline with a Naive Bayes classifier\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('to_dense', to_dense_transformer),\n",
    "                           ('classifier', GaussianNB())])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Gaussian Naive Bayes accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbf6f7",
   "metadata": {},
   "source": [
    "**Feedforward Neural Networks (FNNs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaafada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "218/218 [==============================] - 1s 1ms/step - loss: 0.4944 - accuracy: 0.7626\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.4207 - accuracy: 0.7939\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8080\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8146\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8155\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8224\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8333\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8343\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8356\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8458\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7826\n",
      "Feedforward Neural Networks accuracy: 0.7826337218284607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocessing the data\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "y_processed = to_categorical(y)  # Use this for classification. For regression, you don't need to_categorical\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "# Neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_processed.shape[1], activation='softmax'))  # Use 'softmax' for classification, 'linear' for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use 'mean_squared_error' for regression\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Feedforward Neural Networks accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2c36c",
   "metadata": {},
   "source": [
    "**Stacking Ensemble Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d6f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 0.7998849913743531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.77      0.79       861\n",
      "        True       0.79      0.83      0.81       878\n",
      "\n",
      "    accuracy                           0.80      1739\n",
      "   macro avg       0.80      0.80      0.80      1739\n",
      "weighted avg       0.80      0.80      0.80      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = df.drop('Transported', axis=1)\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-learner\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "# Create the stacking model\n",
    "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Create a pipeline with the stacked model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', stacked_model)])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Stacked Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6498b3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Model Accuracy: 0.7941345600920069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.76      0.79       861\n",
      "        True       0.78      0.82      0.80       878\n",
      "\n",
      "    accuracy                           0.79      1739\n",
      "   macro avg       0.80      0.79      0.79      1739\n",
      "weighted avg       0.79      0.79      0.79      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame here\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Define the selected features\n",
    "selected_features = ['HomePlanet', 'CryoSleep', 'Age', 'VIP', 'RoomService', \n",
    "                     'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'FirstNameInitial', \n",
    "                     'SurnameInitial', 'deck', 'num', 'Group', 'Group_size', 'All_Zero']\n",
    "\n",
    "# Ensure that df contains the selected features\n",
    "X = df[selected_features]\n",
    "y = df['Transported']\n",
    "\n",
    "# Defining numerical and categorical features within the selected features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Creating a column transformer for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42)),\n",
    "    ('svc', SVC(probability=True, random_state=42))\n",
    "]\n",
    "\n",
    "# Define meta-learner\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "# Create the stacking model\n",
    "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Create a pipeline with the stacked model\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', stacked_model)])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Stacked Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1113178e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assuming df_new is your new DataFrame and it has the same structure as df\n",
    "# Ensure that df_new contains the selected features\n",
    "\n",
    "\n",
    "X_new = df[selected_features]\n",
    "\n",
    "# Preprocess and predict using the trained model\n",
    "y_pred_new = pipeline.predict(X_new)\n",
    "\n",
    "# Import ST_test.csv\n",
    "ST_test = pd.read_csv('ST_test.csv')\n",
    "\n",
    "# Check if ST_test has the same number of rows as y_pred_new\n",
    "if len(ST_test) == len(y_pred_new):\n",
    "    # Append the predicted values to ST_test.csv\n",
    "    ST_test['Transported'] = y_pred_new\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "\n",
    "    # Keep only the PassengerId and Transported columns\n",
    "    ST_test_result = ST_test[['PassengerId', 'Transported']]\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    ST_test_result.to_csv('ST_test_result2.csv', index=False)\n",
    "else:\n",
    "    print(\"Error: The length of ST_test and predicted values does not match.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
